# -*- coding: utf-8 -*-
"""Car_Price_Feature_Engineering.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Hy4Ypjbb0gttrD6Oax7XnkWwMDAyAc-

# **Feature Engineering and Data Preprocessing on Car Price Prediction Dataset**
### Name: Swapnil Santosh Akhade
### Dept: AIML (A1)
### Date: 2 Nov 2025

This notebook performs data preprocessing and feature engineering steps on a car price prediction dataset obtained from Kaggle. The steps include handling missing data, encoding categorical variables, feature scaling, feature selection using SelectKBest, and dimensionality reduction using PCA.

Installing and Importing Libraries
"""

!pip install kagglehub

import pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, f_regression
import matplotlib.pyplot as plt
import seaborn as sns

"""Download Dataset from Kaggle"""

import kagglehub

# Download latest version
path = kagglehub.dataset_download("zafarali27/car-price-prediction")

print("Path to dataset files:", path)

"""Load the .csv"""

import os

file_path = os.path.join(path, "car_price_prediction_.csv")
df = pd.read_csv(file_path)
df.head()

"""Exploring the Data"""

df.info()
df.describe()
df.isnull().sum()
df.nunique()

"""Check for NULL values"""

sns.heatmap(df.isnull(), cbar=False)
plt.show()

"""Handling Missing Values"""

# Numerical columns → fill with mean
num_cols = df.select_dtypes(include=['int64', 'float64']).columns
for col in num_cols:
    df[col] = df[col].fillna(df[col].mean())

# Categorical columns → fill with mode
cat_cols = df.select_dtypes(include=['object']).columns
for col in cat_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

"""Check with columns"""

cat_cols = df.select_dtypes(include=['object']).columns
print("Categorical Columns:\n", cat_cols.tolist())

"""Check Unique Values"""

for col in ['Brand', 'Fuel Type', 'Transmission', 'Condition', 'Model']:
    print(f"{col}: {df[col].nunique()} unique values")

"""Encode “Transmission” (binary column)"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Transmission'] = le.fit_transform(df['Transmission'])

print("Unique values after encoding:")
print(df['Transmission'].unique())

"""Encode “Condition” (3 unique values)"""

df = pd.get_dummies(df, columns=['Condition'], drop_first=True)

df.columns

"""Encode “Fuel Type” (4 unique values)"""

df = pd.get_dummies(df, columns=['Fuel Type'], drop_first=True)

df.columns

"""Encode “Brand” (7 unique values)"""

df = pd.get_dummies(df, columns=['Brand'], drop_first=True)

df.columns

"""Encode “Model” (28 unique values)"""

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df['Model'] = le.fit_transform(df['Model'])

df.head()

"""### Feature Scaling (Standardization)
Separate Features (X) and Target (y)
"""

X = df.drop(columns=['Price', 'Car ID'])  # Features
y = df['Price']                           # Target

"""Scale the Feature Columns"""

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

"""Convert Back to a DataFrame (Optional, for readability)"""

import pandas as pd

X_scaled = pd.DataFrame(X_scaled, columns=X.columns)
X_scaled.head()

"""### Feature Selection using SelectKBest
Import and Apply SelectKBest
"""

from sklearn.feature_selection import SelectKBest, f_regression

# Select top 10 features most correlated with Price
selector = SelectKBest(score_func=f_regression, k=10)
X_new = selector.fit_transform(X_scaled, y)

# Get selected feature names
selected_features = X.columns[selector.get_support()]
print("Top 10 Selected Features:")
print(selected_features)

"""View the Reduced Dataset"""

X_selected = pd.DataFrame(X_new, columns=selected_features)
X_selected.head()

"""### PCA Implementation
Import PCA and Apply It
"""

from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import numpy as np

# Apply PCA to reduce dimensions
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

print("Explained Variance Ratio:", pca.explained_variance_ratio_)

"""Visualize PCA Components"""

plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.title('PCA Visualization of Car Dataset')
plt.colorbar(label='Price')
plt.show()

"""Check How Many Components Explain Most Variance"""

pca_full = PCA().fit(X_scaled)
plt.plot(np.cumsum(pca_full.explained_variance_ratio_))
plt.xlabel('Number of Components')
plt.ylabel('Cumulative Explained Variance')
plt.title('Explained Variance by Components')
plt.grid(True)
plt.show()